{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NGCF.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SytzeAndr/NGCF_RP32/blob/master/NGCF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Yt4bUlkamn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random as rd\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni4rEp2I06Rd",
        "colab_type": "text"
      },
      "source": [
        "**File loading**\n",
        "\n",
        "Here we use the Google Drive mountpoint to load files. For this to work, note the following:\n",
        "\n",
        "\n",
        "\n",
        "*   The first time you execute this, it will provide a link, which you need to follow and give permission for Colab to access your Google Drive.\n",
        "*   Make sure that the data is located in the folder `RP_data` which should be located in the root of your Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GuQIsFhz_O6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "6b10e2b4-86e5-4007-8e8f-9794c56c421d"
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "data_path = './drive/My Drive/RP_data'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFlr-rxYnsid",
        "colab_type": "text"
      },
      "source": [
        "**Data class**\n",
        "\n",
        "The Data class is a utility class that will help loading the data, compute useful properties of the data and create sample batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "20UOLdQ9rdyX",
        "colab": {}
      },
      "source": [
        "class Data(object):\n",
        "  def __init__(self, path, batch_size):\n",
        "    self.path = path\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "    train_file = path + '/train.txt'\n",
        "    test_file = path + '/test.txt'\n",
        "\n",
        "    self.n_train = 0\n",
        "    self.n_test = 0\n",
        "    self.exist_users = []\n",
        "    self.train_items = {}\n",
        "    self.test_items = {}\n",
        "\n",
        "    with open(train_file) as f:\n",
        "      for l in f.readlines():\n",
        "        if len(l) > 0:\n",
        "          l = l.strip('\\n')\n",
        "          items = [int(i) for i in l.split(' ')]\n",
        "          uid, train_items = items[0], items[1:]\n",
        "          self.exist_users.append(uid)\n",
        "          self.train_items[uid] = train_items\n",
        "          self.n_train += len(train_items)\n",
        "\n",
        "    with open(test_file) as f:\n",
        "      for l in f.readlines():\n",
        "        if len(l) > 0:\n",
        "          l = l.strip('\\n')\n",
        "          try:\n",
        "            items = [int(i) for i in l.split(' ')]\n",
        "            uid, test_items = items[0], items[1:]\n",
        "            self.exist_users.append(uid)\n",
        "            self.test_items[uid] = test_items\n",
        "            self.n_test += len(test_items)\n",
        "          except Exception:\n",
        "            continue\n",
        "\n",
        "    train_max_item = max([max(items) for items in list(self.train_items.values())])\n",
        "    test_max_item = max([max(items) for items in list(self.test_items.values())])\n",
        "    self.n_items = max(train_max_item, test_max_item)\n",
        "    self.n_users = max(self.exist_users)\n",
        "  \n",
        "\n",
        "  def sample(self):\n",
        "    if self.batch_size <= self.n_users:\n",
        "      users = rd.sample(self.exist_users, self.batch_size)\n",
        "    else:\n",
        "      users = [rd.choice(self.exist_users) for _ in range(self.batch_size)]\n",
        "\n",
        "\n",
        "    def sample_pos_items_for_u(u, num):\n",
        "      pos_items = self.train_items[u]\n",
        "      n_pos_items = len(pos_items)\n",
        "      pos_batch = []\n",
        "      while True:\n",
        "        if len(pos_batch) == num: break\n",
        "        pos_id = np.random.randint(low=0, high=n_pos_items, size=1)[0]\n",
        "        pos_i_id = pos_items[pos_id]\n",
        "\n",
        "        if pos_i_id not in pos_batch:\n",
        "          pos_batch.append(pos_i_id)\n",
        "      return pos_batch\n",
        "\n",
        "\n",
        "    def sample_neg_items_for_u(u, num):\n",
        "      neg_batch = []\n",
        "      while True:\n",
        "        if len(neg_batch) == num: break\n",
        "        neg_id = np.random.randint(low=0, high=self.n_items, size=1)[0]\n",
        "        if neg_id not in self.train_items[u] and neg_id not in neg_batch:\n",
        "          neg_batch.append(neg_id)\n",
        "      return neg_batch\n",
        "    \n",
        "\n",
        "    pos_items, neg_items = [], []\n",
        "    for u in users:\n",
        "      pos_items += sample_pos_items_for_u(u, 1)\n",
        "      neg_items += sample_neg_items_for_u(u, 1)\n",
        "\n",
        "    return users, pos_items, neg_items\n",
        "\n",
        "data = Data(data_path, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2iFaHvdvc8J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "f22f8a66-fada-461c-a16f-95470cf8c1fd"
      },
      "source": [
        "data.sample()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([23323, 42808, 25158, 13144, 34845, 46601, 15128, 3246, 42544, 43562],\n",
              " [66111, 5260, 58472, 47765, 64092, 58786, 19457, 8990, 52296, 58227],\n",
              " [38466, 49956, 45615, 25744, 2817, 71553, 42324, 56610, 56784, 90067])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frx1uCxdNYWU",
        "colab_type": "text"
      },
      "source": [
        "#The steps to take\n",
        "As a rough outline, we can sketch the steps to be taken to train a Neural Graph Collaborative Filtering system as follows. \n",
        "1. Create a user-item interaction graph from our data.\n",
        "2. Perform message constructing by implementing the message passing formula, which defines the relations between users and items. We then use message aggregation to create a representation for each user, which defines our first-order propagation. \n",
        "3. Use the representations from the first order-representation to create higher order representations.\n",
        "4. Use embeddings obtained from our L layers to train a neural network, using theory about graph neural networks.\n",
        "5. Make a prediction on our test sets and measure the recall and normalized discounted cumulative gain (ndcg), which should produce a table.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tn_xzVLBUaMS",
        "colab_type": "text"
      },
      "source": [
        "# step 1\n",
        "The initial embedding is already performed in the data sets and thus we can consider to already have our embedding table. In the paper's work, it is explained that in their NGCF framework the embeddings are refined by propagating them on the user-item interaction graph. \n",
        "\n",
        "This implies that we need to construct an interaction graph, and update its weights according to the message construction/message aggregation functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z0bqsE0VsKc",
        "colab_type": "text"
      },
      "source": [
        "By using PyTorch and PyTorch Geometric (PyG) we are able to construct a graph neural network and perform various operations. We are planning to use this framework. \n",
        "\n",
        "## GCN with torch_geometric (PyG)\n",
        "Some of its steps are described in this blog post:\n",
        "https://towardsdatascience.com/hands-on-graph-neural-networks-with-pytorch-pytorch-geometric-359487e221a8\n",
        "\n",
        "There is also a google colab which trains a GCN to identify 'spammers'\n",
        "https://colab.research.google.com/github/zaidalyafeai/Notebooks/blob/master/Deep_GCN_Spam.ipynb#scrollTo=_4_eVOI2M4Uo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sUDqw3zY7AD",
        "colab_type": "text"
      },
      "source": [
        "First we need to install torch_geometric. This is a geometric deep learning extension library for PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m23H3JzIjE8E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "6b548822-c2fe-4236-ee0a-71e17ba8f87b"
      },
      "source": [
        "pip install torch===1.2.0 torchvision===0.4.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch===1.2.0 in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: torchvision===0.4.0 in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch===1.2.0) (1.17.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision===0.4.0) (6.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision===0.4.0) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfAzbMDlfg93",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "845fc41d-880a-44d4-d0a4-90aef75d3710"
      },
      "source": [
        "import torch\n",
        "# we use torch version 1.2.0 instead of the latest due to dependency errors\n",
        "print(torch.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mo9WkaqnqEI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3e4ec8e4-2339-4d8a-b589-dbc5ff7c29e3"
      },
      "source": [
        "# these were the corresponding versions for torch-geometric 1.3.2, released 4 oct 2019, which runs on torch 1.2.0.\n",
        "!pip install torch-scatter==1.3.1\n",
        "!pip install torch-sparse==0.4.0\n",
        "!pip install torch-cluster==1.4.4\n",
        "!pip install torch-spline-conv==1.1.0\n",
        "!pip install torch-geometric==1.3.2"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch-scatter==1.3.1\n",
            "  Downloading https://files.pythonhosted.org/packages/35/d4/750403a8aa32cdb3d2d05849c6a10e4e0604de5e0cc94b81a0d0d69a75f3/torch_scatter-1.3.1.tar.gz\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-1.3.1-cp36-cp36m-linux_x86_64.whl size=2726045 sha256=9a31666bfe71bc02e93eb5e865f671d7f2b4a1041dcfec5df6933be8451318d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/21/0b/c42fa9353ceec5e87464599e470a03e4250ec667b4a392fa7d\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "  Found existing installation: torch-scatter 2.0.4\n",
            "    Uninstalling torch-scatter-2.0.4:\n",
            "      Successfully uninstalled torch-scatter-2.0.4\n",
            "Successfully installed torch-scatter-1.3.1\n",
            "Collecting torch-sparse==0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/0a/2ff678e0d04e524dd2cf990a6202ced8c0ffe3fe6b08e02f25cc9fd27da0/torch_sparse-0.4.0.tar.gz\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-sparse==0.4.0) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-sparse==0.4.0) (1.17.5)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.4.0-cp36-cp36m-linux_x86_64.whl size=3553274 sha256=0d64496fb09c441d26ba3fffcd5ab750495c025277cb8445f031aa1411ef13a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/9d/83/0a/38ea460df5586a075b877fe089619e5238487712a0645940bd\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "  Found existing installation: torch-sparse 0.6.0\n",
            "    Uninstalling torch-sparse-0.6.0:\n",
            "      Successfully uninstalled torch-sparse-0.6.0\n",
            "Successfully installed torch-sparse-0.4.0\n",
            "Collecting torch-cluster==1.4.4\n",
            "  Downloading https://files.pythonhosted.org/packages/bd/5f/01c5799cd1f81f9956f03a0e1d9a861e020a598dd411d9bd3c3c1dd5b8a4/torch_cluster-1.4.4.tar.gz\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-cluster==1.4.4) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-cluster==1.4.4) (1.17.5)\n",
            "Building wheels for collected packages: torch-cluster\n",
            "  Building wheel for torch-cluster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-cluster: filename=torch_cluster-1.4.4-cp36-cp36m-linux_x86_64.whl size=14442687 sha256=0532a0a9a3208355314c51b01c9e849cd455816a5085ea32c4a13c8e09d3ef06\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/7b/ab/b3e266920055d1e51988f93a99ef8df62e399b234c8d50527f\n",
            "Successfully built torch-cluster\n",
            "Installing collected packages: torch-cluster\n",
            "  Found existing installation: torch-cluster 1.5.0\n",
            "    Uninstalling torch-cluster-1.5.0:\n",
            "      Successfully uninstalled torch-cluster-1.5.0\n",
            "Successfully installed torch-cluster-1.4.4\n",
            "Collecting torch-spline-conv==1.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/3c/dd/daa9d0b7b2ede913e573876ae286a58ec296678858f2814ff6d6789b234f/torch_spline_conv-1.1.0.tar.gz\n",
            "Building wheels for collected packages: torch-spline-conv\n",
            "  Building wheel for torch-spline-conv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-spline-conv: filename=torch_spline_conv-1.1.0-cp36-cp36m-linux_x86_64.whl size=4974031 sha256=23510558ecda6a077c294b33055bc0e3974b55726117e2e8bec2f67a12c74d80\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/00/1f/9c414a9a5f340dd8d2e5e362d1bb5cad91fc7aec78c935fd66\n",
            "Successfully built torch-spline-conv\n",
            "Installing collected packages: torch-spline-conv\n",
            "  Found existing installation: torch-spline-conv 1.2.0\n",
            "    Uninstalling torch-spline-conv-1.2.0:\n",
            "      Successfully uninstalled torch-spline-conv-1.2.0\n",
            "Successfully installed torch-spline-conv-1.1.0\n",
            "Requirement already satisfied: torch-geometric==1.3.2 in /usr/local/lib/python3.6/dist-packages (1.3.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from torch-geometric==1.3.2) (2.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-geometric==1.3.2) (1.17.5)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.6/dist-packages (from torch-geometric==1.3.2) (4.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torch-geometric==1.3.2) (0.22.1)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (from torch-geometric==1.3.2) (0.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-geometric==1.3.2) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torch-geometric==1.3.2) (0.25.3)\n",
            "Requirement already satisfied: plyfile in /usr/local/lib/python3.6/dist-packages (from torch-geometric==1.3.2) (0.7.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torch-geometric==1.3.2) (2.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torch-geometric==1.3.2) (2.21.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->torch-geometric==1.3.2) (4.4.1)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric==1.3.2) (0.6.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric==1.3.2) (2.4.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torch-geometric==1.3.2) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric==1.3.2) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric==1.3.2) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->torch-geometric==1.3.2) (1.12.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric==1.3.2) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric==1.3.2) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric==1.3.2) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric==1.3.2) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErcV2T7PWLDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch_geometric"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp8OSLE3qZnC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a87b655a-52a3-409d-a6a8-995e5d3d787d"
      },
      "source": [
        "# verify that torch geometric is imported, should be 1.3.2\n",
        "print(torch_geometric.__version__)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsVTP8uXrkNV",
        "colab_type": "text"
      },
      "source": [
        "**todo: create a graph by following the steps from either the blogpost or the google colab file linked earlier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDlCsjl7Spjl",
        "colab_type": "text"
      },
      "source": [
        "# step 2\n",
        "For each user-item pair (u,i), we define the message from i to u as\n",
        "\n",
        "$m_{u \\leftarrow i} = \\dfrac{1}{\\sqrt{|N_u||N_i|}} (W_1 e_i + W_2(e_i \\odot e_u))$\n",
        "\n",
        "Where $N_u, N_i$ are the first hop neighbors of $u$ and $i$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw-Ra9oKSwED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}